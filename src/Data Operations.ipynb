{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_words(df):\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    \n",
    "    sentence = []\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        if str(df.loc[i].word) != \"nan\":\n",
    "            sentence.append(df.loc[i].word)\n",
    "            labels.append(df.loc[i].label)\n",
    "        else:\n",
    "            s = \" \".join(sentence)\n",
    "            l = \" \".join(labels)\n",
    "            sentences.append(s)\n",
    "            tags.append(l)\n",
    "            sentence = []\n",
    "            labels = []\n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(df):\n",
    "    ss = []\n",
    "    tt = []\n",
    "    pp = []\n",
    "    nn = []\n",
    "    for i in range(len(df)):\n",
    "        sentence_tokens = df.loc[i].Sentence.split()\n",
    "        tag_tokens = df.loc[i].Tag.split()\n",
    "        pos_tokens = df.loc[i].POS.split()\n",
    "        number_tokens = len(sentence_tokens) * [\"Sentence: %s\" % i]\n",
    "        ss.append(sentence_tokens)\n",
    "        tt.append(tag_tokens)\n",
    "        pp.append(pos_tokens)\n",
    "        nn.append(number_tokens)\n",
    "    ss = list(itertools.chain.from_iterable(ss))\n",
    "    tt = list(itertools.chain.from_iterable(tt))\n",
    "    pp = list(itertools.chain.from_iterable(pp))\n",
    "    nn = list(itertools.chain.from_iterable(nn))\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final[\"Sentence Number\"] = nn\n",
    "    df_final[\"Word\"] = ss\n",
    "    df_final[\"Tag\"] = tt\n",
    "    df_final[\"POS\"] = pp\n",
    "    return df_final\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def parse_data(df):\n",
    "    sentences, tags = merge_words(df)\n",
    "    \n",
    "    df_sentence = pd.DataFrame()\n",
    "    df_sentence[\"Sentence\"] = sentences\n",
    "    df_sentence[\"Tag\"] = tags\n",
    "    \n",
    "    df_sentence[\"POS\"] = df_sentence.Sentence.apply(lambda x: \" \".join(token[-1] for token in nltk.pos_tag(x.split())))\n",
    "\n",
    "    df_sentence = split_sentences(df_sentence)\n",
    "    return df_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ilke/Desktop/ner-interview-question/data/\"\n",
    "engtrain = pd.read_csv(\"%sengtrain.bio.txt\" % DATA_PATH, sep=\"\\t\", header=None, skip_blank_lines=False)\n",
    "engtest = pd.read_csv(\"%sengtest.bio.txt\" % DATA_PATH, sep=\"\\t\", header=None, skip_blank_lines=False)\n",
    "trivia_train = pd.read_csv(\"%strivia10k13train.bio.txt\" % DATA_PATH, header=None, sep=\"\\t\", skip_blank_lines=False)\n",
    "trivia_test = pd.read_csv(\"%strivia10k13test.bio.txt\" % DATA_PATH, header=None, sep=\"\\t\", skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "engtrain.columns = [\"label\", \"word\"]\n",
    "engtest.columns = [\"label\", \"word\"]\n",
    "trivia_train.columns = [\"label\", \"word\"]\n",
    "trivia_test.columns = [\"label\", \"word\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Check Datasets for Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-Actor', 'I-Actor', 'O', 'B-Plot', 'I-Plot', 'B-Opinion',\n",
       "       'I-Opinion', nan, 'B-Award', 'I-Award', 'B-Year', 'B-Genre',\n",
       "       'B-Origin', 'I-Origin', 'B-Director', 'I-Director', 'I-Genre',\n",
       "       'I-Year', 'B-Soundtrack', 'I-Soundtrack', 'B-Relationship',\n",
       "       'I-Relationship', 'B-Character_Name', 'I-Character_Name',\n",
       "       'B-Quote', 'I-Quote'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trivia_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-ACTOR', 'I-ACTOR', nan, 'B-YEAR', 'B-TITLE', 'B-GENRE',\n",
       "       'I-GENRE', 'B-DIRECTOR', 'I-DIRECTOR', 'B-SONG', 'I-SONG',\n",
       "       'B-PLOT', 'I-PLOT', 'B-REVIEW', 'B-CHARACTER', 'I-CHARACTER',\n",
       "       'B-RATING', 'B-RATINGS_AVERAGE', 'I-RATINGS_AVERAGE', 'I-TITLE',\n",
       "       'I-RATING', 'B-TRAILER', 'I-TRAILER', 'I-REVIEW', 'I-YEAR'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engtrain.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_train.label = trivia_train.label.replace(\"B-Character_Name\", \"B-CHARACTER\").replace(\"I-Character_Name\", \"I-CHARACTER\").replace(\"B-Soundtrack\", \"B-SONG\").replace(\"I-Soundtrack\", \"I-SONG\")\n",
    "trivia_test.label = trivia_test.label.replace(\"B-Character_Name\", \"B-CHARACTER\").replace(\"I-Character_Name\", \"I-CHARACTER\").replace(\"B-Soundtrack\", \"B-SONG\").replace(\"I-Soundtrack\", \"I-SONG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([engtrain, trivia_train])\n",
    "test = pd.concat([engtest, trivia_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = parse_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = parse_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing Touches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Number</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>what</td>\n",
       "      <td>O</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>movies</td>\n",
       "      <td>O</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>star</td>\n",
       "      <td>O</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>bruce</td>\n",
       "      <td>B-ACTOR</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sentence: 0</td>\n",
       "      <td>willis</td>\n",
       "      <td>I-ACTOR</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentence Number    Word      Tag  POS\n",
       "0     Sentence: 0    what        O   WP\n",
       "1     Sentence: 0  movies        O  NNS\n",
       "2     Sentence: 0    star        O  VBP\n",
       "3     Sentence: 0   bruce  B-ACTOR   NN\n",
       "4     Sentence: 0  willis  I-ACTOR   NN"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.Tag = train_final.Tag.str.upper()\n",
    "test_final.Tag = test_final.Tag.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-ACTOR', 'I-ACTOR', 'B-YEAR', 'B-TITLE', 'B-GENRE',\n",
       "       'I-GENRE', 'B-DIRECTOR', 'I-DIRECTOR', 'B-SONG', 'I-SONG',\n",
       "       'B-PLOT', 'I-PLOT', 'B-REVIEW', 'B-CHARACTER', 'I-CHARACTER',\n",
       "       'B-RATING', 'B-RATINGS_AVERAGE', 'I-RATINGS_AVERAGE', 'I-TITLE',\n",
       "       'I-RATING', 'B-TRAILER', 'I-TRAILER', 'I-REVIEW', 'I-YEAR',\n",
       "       'B-OPINION', 'I-OPINION', 'B-AWARD', 'I-AWARD', 'B-ORIGIN',\n",
       "       'I-ORIGIN', 'B-RELATIONSHIP', 'I-RELATIONSHIP', 'B-QUOTE',\n",
       "       'I-QUOTE'], dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.Tag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.Tag = train_final.Tag.replace(\"B-RATINGS_AVERAGE\", \"B-RATING\").replace(\"I-RATINGS_AVERAGE\", \"I-RATING\")\n",
    "test_final.Tag = test_final.Tag.replace(\"B-RATINGS_AVERAGE\", \"B-RATING\").replace(\"I-RATINGS_AVERAGE\", \"I-RATING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.to_excel(\"%sner_train.xlsx\" % DATA_PATH)\n",
    "test_final.to_excel(\"%sner_test.xlsx\" % DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
